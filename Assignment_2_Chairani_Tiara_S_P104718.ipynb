{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2_Chairani Tiara S_P104718",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e84TJ9hZd81c"
      },
      "source": [
        "ASSIGNMENT 2 -\n",
        "Name : Chairani Tiara Sayyu\n",
        "Matrix Name : P104718"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_3O6Fufi_og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "964155ed-bb9a-4b5a-a852-f927826b8be3"
      },
      "source": [
        "import sys\n",
        "import nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR2iQfGPdjcH"
      },
      "source": [
        "READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVo5ZIhkjHd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "2518664e-534c-4b7c-fbfa-b8f5b6bc6913"
      },
      "source": [
        "df = pd.read_csv('dataset.csv')\n",
        "df = df[['text','humor']]\n",
        "df = df[pd.notnull(df['text'])]\n",
        "df.rename(columns = {'text':'text'}, inplace = True)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you call a turtle without its shell? d...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5 reasons the 2016 election feels so personal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Martha stewart tweets hideous food photo, twit...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is a pokemon master's favorite kind of pa...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why do native americans hate it when it rains ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Obama's climate change legacy is impressive, i...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>My family tree is a cactus, we're all pricks.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor\n",
              "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
              "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
              "2  What do you call a turtle without its shell? d...   True\n",
              "3      5 reasons the 2016 election feels so personal  False\n",
              "4  Pasco police shot mexican migrant from behind,...  False\n",
              "5  Martha stewart tweets hideous food photo, twit...  False\n",
              "6  What is a pokemon master's favorite kind of pa...   True\n",
              "7  Why do native americans hate it when it rains ...   True\n",
              "8  Obama's climate change legacy is impressive, i...  False\n",
              "9      My family tree is a cactus, we're all pricks.   True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2zevQ8kjRES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502e8493-9269-4933-f37a-62da75c142b1"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saNVRJHOjYtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c42f7a-6560-4ad3-85c5-66c397212d8f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 200000 entries, 0 to 199999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    200000 non-null  object\n",
            " 1   humor   200000 non-null  bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 3.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt0DUPbPja8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27204865-39c7-48a6-8c4b-764c005f0843"
      },
      "source": [
        "df.index = range(200000)\n",
        "df['text'].apply(lambda x: len(x.split(' '))).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2398856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8e7TxDYjdJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "340c1e4b-e7bc-40b1-e441-9cf3e172142a"
      },
      "source": [
        "cnt_pro = df['humor'].value_counts()\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\n",
        "plt.ylabel('Short Text', fontsize=12)\n",
        "\n",
        "plt.xlabel('Humor Type', fontsize=12)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49hN7KgpjfZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feed5358-3438-4f32-e7a5-5f883fca6e58"
      },
      "source": [
        "def print_requirementFeedback(index):\n",
        "    #example = df[df.index == index][['text', 'humor']].values[0]\n",
        "    example = df[df.index == index][['text', 'humor']].values[0]\n",
        "    if len(example) > 0:\n",
        "        print(example[0])\n",
        "        print('Humor Type:', example[1])\n",
        "print_requirementFeedback(12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Want to know why athletes chose to #takeaknee? look at our broken justice system\n",
            "Humor Type: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNJac--NdnYf"
      },
      "source": [
        "DATA PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzIV9PTSMFY_"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "def cleanText(text):\n",
        "    text = BeautifulSoup(text, \"lxml\").text\n",
        "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
        "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
        "    text = text.lower()\n",
        "    text = text.replace('x', '')\n",
        "    return text\n",
        "df['text'] = df['text'].apply(cleanText)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUtmrkkaMKeU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "34dcaf47-73b4-47d5-8b63-a501695ff6f5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>watch: darvish gave hitter whiplash with slow ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what do you call a turtle without its shell? d...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5 reasons the 2016 election feels so personal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pasco police shot meican migrant from behind, ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor\n",
              "0  joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
              "1  watch: darvish gave hitter whiplash with slow ...  False\n",
              "2  what do you call a turtle without its shell? d...   True\n",
              "3      5 reasons the 2016 election feels so personal  False\n",
              "4  pasco police shot meican migrant from behind, ...  False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJvEqCVgMM_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28cfebff-9003-4ddd-daf1-6e8b95bf9eb8"
      },
      "source": [
        "df['text'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    joe biden rules out 2020 bid: 'guys, i'm not r...\n",
              "1    watch: darvish gave hitter whiplash with slow ...\n",
              "2    what do you call a turtle without its shell? d...\n",
              "3        5 reasons the 2016 election feels so personal\n",
              "4    pasco police shot meican migrant from behind, ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzTzsFiwM9TF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ee32e6-e96a-4c8d-b63d-cd29258a71cb"
      },
      "source": [
        "nltk.download('punkt')\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word.lower())\n",
        "    return tokens\n",
        "\n",
        "train_tagged = train.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.humor]), axis=1)\n",
        "test_tagged = test.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.humor]), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLxi8dhddsus"
      },
      "source": [
        "FEATURE EXTRACTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFImGpDyOL3u"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPOWe841LMUB"
      },
      "source": [
        "FEATURE - DOC2VEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnLJzgQeLDdx"
      },
      "source": [
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJWneIrALNxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4bb0d87-0b92-4aea-d039-97b45bdbaf12"
      },
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000/160000 [00:00<00:00, 2268248.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RuTqQJrLPb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842699a2-749e-4c93-a5d4-abd10ddd6129"
      },
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000/160000 [00:00<00:00, 2535739.92it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2252126.45it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2336236.61it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2609442.68it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2575730.84it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2593489.08it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2627773.34it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2584808.42it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2501569.85it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2605956.95it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2476844.53it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2682777.09it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2612805.49it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2535356.72it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2434197.00it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2394590.01it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2522813.75it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2444010.56it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2633992.62it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2551085.84it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2570698.82it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2593148.35it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2501346.08it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2554776.31it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2522500.82it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2376275.23it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2663568.07it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2625881.43it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2575463.94it/s]\n",
            "100%|██████████| 160000/160000 [00:00<00:00, 2674416.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8min 52s, sys: 50.5 s, total: 9min 43s\n",
            "Wall time: 5min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H7DF9LjLSYw"
      },
      "source": [
        "#Building the Final Vector Feature for the Classifier\n",
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3YIRClqLUYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed5262f-0c4c-4db5-cc17-e710de16cf41"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "#dataset\n",
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
        "\n",
        "#Train the Logistic Regression Classifier.\n",
        "logreg = LogisticRegression(solver='lbfgs', max_iter=400)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Testing accuracy LR %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score LR (DOC2VEC): {}'.format(f1_score(y_test, y_pred, average='macro')))\n",
        "print('Testing Precision score LR (DOC2VEC): {}'.format(precision_score(y_test, y_pred, average='macro')))\n",
        "print('Testing Recall score LR(DOC2VEC): {}'.format(recall_score(y_test, y_pred, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy LR 0.647375\n",
            "Testing F1 score LR (DOC2VEC): 0.6473644295283778\n",
            "Testing Precision score LR (DOC2VEC): 0.647392239171936\n",
            "Testing Recall score LR(DOC2VEC): 0.6473747278684368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Zp-XuuLffz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85459b94-ca5a-49f8-c603-120299eda860"
      },
      "source": [
        "#NB classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "cNB = GaussianNB()\n",
        "cNB.fit(X_train, y_train) \n",
        "y_pred_NB = cNB.predict(X_test)\n",
        "print('Testing accuracy NB %s' % accuracy_score(y_test, y_pred_NB))\n",
        "print('Testing F1 score NB (DOC2VEC): {}'.format(f1_score(y_test, y_pred_NB, average='macro')))\n",
        "print('Testing Precision score NB (DOC2VEC): {}'.format(precision_score(y_test, y_pred_NB, average='macro')))\n",
        "print('Testing Recall score NB(DOC2VEC): {}'.format(recall_score(y_test, y_pred_NB, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy NB 0.62755\n",
            "Testing F1 score NB (DOC2VEC): 0.6260964415035148\n",
            "Testing Precision score NB (DOC2VEC): 0.6295599371444747\n",
            "Testing Recall score NB(DOC2VEC): 0.6275468840688672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IDGuYeeLekS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca383ba2-e27a-4833-b2b4-2f4690f23ce0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "#dataset\n",
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
        "\n",
        "#SVM :https://scikit-learn.org/stable/modules/svm.html\n",
        "#SVM classifier\n",
        "from sklearn import svm\n",
        "clf = svm.SVC(gamma='scale')\n",
        "clf.fit(X_train, y_train) \n",
        "y_pred_SVM = clf.predict(X_test)\n",
        "print('Testing accuracy SVM %s' % accuracy_score(y_test, y_pred_SVM))\n",
        "print('Testing F1 score SVM (DOC2VEC): {}'.format(f1_score(y_test, y_pred_SVM, average='macro')))\n",
        "print('Testing Precision score SVM (DOC2VEC): {}'.format(precision_score(y_test, y_pred_SVM, average='macro')))\n",
        "print('Testing Recall score SVM (DOC2VEC): {}'.format(recall_score(y_test, y_pred_SVM, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy SVM 0.636\n",
            "Testing F1 score SVM (DOC2VEC): 0.6359531025685556\n",
            "Testing Precision score SVM (DOC2VEC): 0.6360692403318482\n",
            "Testing Recall score SVM (DOC2VEC): 0.6359994340899986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLv4Pz5BLjNw"
      },
      "source": [
        "FEATURE - TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrWj4WnIOOLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb6d742-cb9e-4169-eca3-90953c8e5e7d"
      },
      "source": [
        "#split-data-train-test\n",
        "from sklearn.model_selection import train_test_split\n",
        "sentences = df['text'].values\n",
        "y = df['humor'].values\n",
        "sentences_train, sentences_test, yyy_train, yyy_test = train_test_split(sentences,y, test_size=0.2, random_state=42)\n",
        "\n",
        "#feature extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "TFIDF = TfidfVectorizer()\n",
        "TFIDF.fit(sentences_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pbmg9O3Pp7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a98ae8-62bc-4e48-d6e3-adf3351ac557"
      },
      "source": [
        "#classification models\n",
        "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
        "\n",
        "XXX_train = TFIDF.transform(sentences_train)\n",
        "XXX_test  = TFIDF.transform(sentences_test)\n",
        "\n",
        "#LR\n",
        "\n",
        "logreg = LogisticRegression(solver='lbfgs', max_iter=400)\n",
        "logreg.fit(XXX_train, yyy_train)\n",
        "ytf_predLR = logreg.predict(XXX_test)\n",
        "print('Testing accuracy LR %s' % accuracy_score(yyy_test, ytf_predLR))\n",
        "print('Testing F1 score LR (TFIDF): {}'.format(f1_score(yyy_test, ytf_predLR, average='macro')))\n",
        "print('Testing Precision score LR (TFIDF): {}'.format(precision_score(yyy_test, ytf_predLR, average='macro')))\n",
        "print('Testing Recall score LR (TFIDF): {}'.format(recall_score(yyy_test, ytf_predLR, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy LR 0.925325\n",
            "Testing F1 score LR (TFIDF): 0.9253246937845725\n",
            "Testing Precision score LR (TFIDF): 0.9253317053072849\n",
            "Testing Recall score LR (TFIDF): 0.9253249010633122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omkCyRS-Wvc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb1867c-50f2-4ef1-c604-1763ea489512"
      },
      "source": [
        "#classification models\n",
        "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
        "\n",
        "XXX_train = TFIDF.transform(sentences_train)\n",
        "XXX_test  = TFIDF.transform(sentences_test)\n",
        "\n",
        "#svm\n",
        "from sklearn import svm\n",
        "cSVM = svm.SVC(gamma='scale')\n",
        "cSVM.fit(XXX_train, yyy_train) \n",
        "ytf_pred_SVM = cSVM.predict(XXX_test)\n",
        "print('Testing accuracy LR %s' % accuracy_score(yyy_test, ytf_pred_SVM))\n",
        "print('Testing F1 score svm (TFIDF): {}'.format(f1_score(yyy_test,ytf_pred_SVM, average='macro')))\n",
        "print('Testing Precision score sVM (TFIDF): {}'.format(precision_score(yyy_test, ytf_pred_SVM, average='macro')))\n",
        "print('Testing Recall score svm (TFIDF): {}'.format(recall_score(yyy_test, ytf_pred_SVM, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy LR 0.938075\n",
            "Testing F1 score svm (TFIDF): 0.9380749996516718\n",
            "Testing Precision score sVM (TFIDF): 0.9380750225230009\n",
            "Testing Recall score svm (TFIDF): 0.9380750060951875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klf4If2gY_LU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404efae1-1dc5-4a4c-e5bb-afb1df4bc626"
      },
      "source": [
        "#classification models\n",
        "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
        "\n",
        "XXX_train = TFIDF.transform(sentences_train)\n",
        "XXX_test  = TFIDF.transform(sentences_test)\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "cNB = MultinomialNB()\n",
        "cNB.fit(XXX_train, yyy_train) \n",
        "ytf_pred_NB = cNB.predict(XXX_test)\n",
        "print('Testing accuracy NB %s' % accuracy_score(yyy_test, ytf_pred_NB))\n",
        "print('Testing F1 score NB (TFIDF): {}'.format(f1_score(yyy_test,ytf_pred_NB, average='macro')))\n",
        "print('Testing Precision score NB (TFIDF): {}'.format(precision_score(yyy_test, ytf_pred_NB, average='macro')))\n",
        "print('Testing Recall score NB (TFIDF): {}'.format(recall_score(yyy_test, ytf_pred_NB, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy NB 0.91645\n",
            "Testing F1 score NB (TFIDF): 0.9164155556863428\n",
            "Testing Precision score NB (TFIDF): 0.9171403082810605\n",
            "Testing Recall score NB (TFIDF): 0.9164510172911275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CA6_c3qLv2b"
      },
      "source": [
        "FEATURE - BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAbigsArdVEg"
      },
      "source": [
        "#split-data-train-test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sentences = df['text'].values\n",
        "y = df['humor'].values\n",
        "sentences_train, sentences_test, yy_train, yy_test = train_test_split(sentences,y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UXqMkuTLwsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff594177-c16b-4cbf-e8ea-2050e10eeba4"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "BOW = CountVectorizer()\n",
        "BOW.fit(sentences_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LULXf0FlL3UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae64fb9e-5a25-4508-d88a-d8218c6b3c35"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "XX_train = BOW.transform(sentences_train)\n",
        "XX_test  = BOW.transform(sentences_test)\n",
        "#LR\n",
        "logreg = LogisticRegression(solver='lbfgs', max_iter=400)\n",
        "logreg.fit(XX_train, yy_train)\n",
        "y_predLR = logreg.predict(XX_test)\n",
        "print('Testing F1 score LR (BOW): {}'.format(f1_score(yy_test, y_predLR, average='macro')))\n",
        "print('Testing Precision score LR (BOW): {}'.format(precision_score(yy_test, y_predLR, average='macro')))\n",
        "print('Testing Recall score LR (BOW): {}'.format(recall_score(yy_test, y_predLR, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing F1 score LR (BOW): 0.9324748723353056\n",
            "Testing Precision score LR (BOW): 0.9324780852652416\n",
            "Testing Recall score LR (BOW): 0.9324749335811874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-wq2w3hL6xE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274eeaf0-9304-4725-c39a-c941078d3ff0"
      },
      "source": [
        "#NB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "cNB = MultinomialNB()\n",
        "cNB.fit(XX_train, yy_train) \n",
        "y_pred_NB = cNB.predict(XX_test)\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "print('Testing F1 score NB (BOW): {}'.format(f1_score(yy_test, y_pred_NB, average='macro')))\n",
        "print('Testing Precision score NB (BOW): {}'.format(precision_score(yy_test, y_pred_NB, average='macro')))\n",
        "print('Testing Recall score NB (BOW): {}'.format(recall_score(yy_test, y_pred_NB, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing F1 score NB (BOW): 0.9199847618870483\n",
            "Testing Precision score NB (BOW): 0.9208746099223496\n",
            "Testing Recall score NB (BOW): 0.9200261235500653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFG37TQoL6Ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265629ab-72cd-46b3-cabe-e5bad14777af"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "XX_train = BOW.transform(sentences_train)\n",
        "XX_test  = BOW.transform(sentences_test)\n",
        "\n",
        "##SVM\n",
        "from sklearn import svm\n",
        "cSVM = svm.SVC(gamma='scale')\n",
        "cSVM.fit(XX_train, yy_train) \n",
        "y_pred_SVM = cSVM.predict(XX_test)\n",
        "\n",
        "print('Testing F1 score SVM (BOW): {}'.format(f1_score(yy_test, y_pred_SVM, average='macro')))\n",
        "print('Testing Precision score SVM (BOW): {}'.format(precision_score(yy_test, y_pred_SVM, average='macro')))\n",
        "print('Testing Recall score SVM (BOW): {}'.format(recall_score(yy_test, y_pred_SVM, average='macro')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing F1 score SVM (BOW): 0.9393238911061874\n",
            "Testing Precision score SVM (BOW): 0.9393565310093654\n",
            "Testing Recall score SVM (BOW): 0.939324788598312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWhbRuTS9WTs"
      },
      "source": [
        "ASSIGNMENT 2 RESULT REPORT: \n",
        "\n",
        "1. For Model with Feature Doc2Vec: \n",
        "- using Logistic Regression Classifier: \n",
        "Testing F1 score LR (DOC2VEC): 0.6473644295283778\n",
        "Testing Precision score LR (DOC2VEC): 0.647392239171936\n",
        "Testing Recall score LR(DOC2VEC): 0.6473747278684368\n",
        "\n",
        "-using NB classifier:\n",
        "Testing F1 score NB (DOC2VEC): 0.6260964415035148\n",
        "Testing Precision score NB (DOC2VEC): 0.6295599371444747\n",
        "Testing Recall score NB(DOC2VEC): 0.6275468840688672\n",
        "\n",
        "-using SVM classifier: \n",
        "Testing F1 score SVM (DOC2VEC): 0.6359531025685556\n",
        "Testing Precision score SVM (DOC2VEC): 0.6360692403318482\n",
        "Testing Recall score SVM (DOC2VEC): 0.6359994340899986\n",
        "\n",
        "2. For Model with Feature TF-IDF: \n",
        "-using Logistic Regression Classifier: \n",
        "Testing F1 score LR (TFIDF): 0.9253246937845725\n",
        "Testing Precision score LR (TFIDF): 0.9253317053072849\n",
        "Testing Recall score LR (TFIDF): 0.9253249010633122\n",
        "\n",
        "-using NB classifier: \n",
        "Testing F1 score NB (TFIDF): 0.9164155556863428\n",
        "Testing Precision score NB (TFIDF): 0.9171403082810605\n",
        "Testing Recall score NB (TFIDF): 0.9164510172911275\n",
        "\n",
        "-using SVM classifier: \n",
        "Testing F1 score svm (TFIDF): 0.9380749996516718\n",
        "Testing Precision score sVM (TFIDF): 0.9380750225230009\n",
        "Testing Recall score svm (TFIDF): 0.9380750060951875\n",
        "\n",
        "3. For Model with Feature BOW: \n",
        "-using Logistic Regression classifier: \n",
        "Testing F1 score LR (BOW): 0.9324748723353056\n",
        "Testing Precision score LR (BOW): 0.9324780852652416\n",
        "Testing Recall score LR (BOW): 0.9324749335811874\n",
        "\n",
        "-using NB classifier: \n",
        "Testing F1 score NB (BOW): 0.9199847618870483\n",
        "Testing Precision score NB (BOW): 0.9208746099223496\n",
        "Testing Recall score NB (BOW): 0.9200261235500653\n",
        "\n",
        "-using SVM classifier: \n",
        "Testing F1 score SVM (BOW): 0.9393238911061874\n",
        "Testing Precision score SVM (BOW): 0.9393565310093654\n",
        "Testing Recall score SVM (BOW): 0.939324788598312\n",
        "\n",
        "\n",
        "Based on the data processing, the best model for SA in this case is with feature BOW with SVM classifier (BOW/SVM) with highest F1 score, Precision score, and Recall Score of 0.939.\n"
      ]
    }
  ]
}